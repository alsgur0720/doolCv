{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (고양이 얼굴 검출기)\n",
    "\n",
    "cat_face_cascade = cv2.CascadeClassifier('haarcascade_frontalcatface_extended.xml')\n",
    "\n",
    "img = cv2.imread('image/cats.jpg', 1)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cat_faces = cat_face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in cat_faces :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (눈, 얼굴 검출기)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('image/aespa.jpg', 1)\n",
    "img = cv2.resize(img, dsize = (0,0), fx = 0.5, fy = 0.5, interpolation = cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "eyes = eye_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "    \n",
    "    \n",
    "for (x,y,w,h) in eyes :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORB 알고리즘(Oriented fast and Rotated Breif)\n",
    "\n",
    "src = cv2.imread('image/apple_book.jpg', 1)\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "target = cv2.imread('image/apple.jpg', 0)\n",
    "\n",
    "orb = cv2.ORB_create(\n",
    "    nfeatures = 40000,\n",
    "    scaleFactor = 1.2,\n",
    "    nlevels = 8,\n",
    "    edgeThreshold = 31,\n",
    "    firstLevel = 0,\n",
    "    WTA_K = 2,\n",
    "    scoreType = cv2.ORB_HARRIS_SCORE,\n",
    "    patchSize = 31,\n",
    "    fastThreshold = 20,\n",
    "    \n",
    ")\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "kp2, des2 = orb.detectAndCompute(target, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "for i in matches[:100]:\n",
    "    idx = i.queryIdx\n",
    "    x1, y1, =  kp1[idx].pt\n",
    "    cv2.circle(src, (int(x1), int(y1)), 3, (255, 0, 0), 3)\n",
    "    \n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K - means clustering (평균 군집화)\n",
    "\n",
    "src = cv2.imread('image/flower.jpg', 1)\n",
    "\n",
    "data = src.reshape(-1,3).astype(np.float32)\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "retval, bestLabels, centers = cv2.kmeans(data, 5, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "centers = centers.astype(np.uint8)\n",
    "dst = centers[bestLabels].reshape(src.shape)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K - nearest neighbor (최근접 이웃)\n",
    "\n",
    "def loadTrainData(image_path, label_path):\n",
    "    \n",
    "    with open(image_path, \"rb\") as image_data:\n",
    "        images = np.frombuffer(image_data.read(), dtype = np.uint8, offset = 16)\n",
    "        \n",
    "    with open(label_path, \"rb\") as label_data:\n",
    "        labels = np.frombuffer(label_data.read(), dtype = np.uint8, offset = 8)\n",
    "        \n",
    "    return images.reshape(-1, 784), labels\n",
    "\n",
    "\n",
    "train_x, train_y = loadTrainData(\n",
    "    \n",
    "    \"./fashion-mnist/train-images-idx3-ubyte\",\n",
    "    \"./fashion-mnist/train-labels-idx1-ubyte\"\n",
    ")\n",
    "\n",
    "test_x, test_y = loadTrainData(\n",
    "    \n",
    "    \"./fashion-mnist/t10k-images-idx3-ubyte\",\n",
    "    \"./fashion-mnist/t10k-labels-idx1-ubyte\"\n",
    ")\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    \n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\",\n",
    "    \n",
    "}\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "retval = knn.train(train_x.astype(np.float32), cv2.ml.ROW_SAMPLE, train_y.astype(np.int32))\n",
    "\n",
    "count = 500\n",
    "\n",
    "retval, results, neighborResponses, dist = knn.findNearest(\n",
    "    test_x[:count].astype(np.float32), k = 7\n",
    "    \n",
    ")\n",
    "\n",
    "matches = results.astype(np.uint8) == test_y[:count][:, None]\n",
    "\n",
    "print(np.count_nonzero(matches) / count * 100)\n",
    "\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    print(\"Index : {}\".format(idx))\n",
    "    print(\"예측값 : {}\".format(label_dict[int(result)]))\n",
    "    print(\"싧제값 : {}\".format(label_dict[test_y[idx]]))\n",
    "    cv2.imshow(\"images\", test_x[idx].reshape(28,28,1))\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
