{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (고양이 얼굴 검출기)\n",
    "\n",
    "cat_face_cascade = cv2.CascadeClassifier('haarcascade_frontalcatface_extended.xml')\n",
    "\n",
    "img = cv2.imread('image/cats.jpg', 1)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cat_faces = cat_face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in cat_faces :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (눈, 얼굴 검출기)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('image/aespa.jpg', 1)\n",
    "img = cv2.resize(img, dsize = (0,0), fx = 0.5, fy = 0.5, interpolation = cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "eyes = eye_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces :\n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "for (x,y,w,h) in eyes :\n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "\n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORB 알고리즘(Oriented fast and Rotated Brief)\n",
    "\n",
    "src = cv2.imread('image/apple_book.jpg', 1)\n",
    "src = cv2.resize(src, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "target = cv2.imread('image/apple.jpg', 0)\n",
    "target = cv2.resize(target, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "orb = cv2.ORB_create(\n",
    "    nfeatures=40000,\n",
    ")\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "kp2, des2 = orb.detectAndCompute(target, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING2, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "for i in matches[:100]:\n",
    "    idx_des1 = i.queryIdx\n",
    "    x1, y1, =  kp1[idx_des1].pt\n",
    "    \n",
    "    idx_des2 = i.trainIdx\n",
    "    x2, y2, =  kp2[idx_des2].pt\n",
    "    \n",
    "    cv2.circle(src, (int(x1), int(y1)), 3, (0, 0, 0), 3)\n",
    "    cv2.circle(target, (int(x2), int(y2)), 3, (255, 0, 0), 3)\n",
    "    \n",
    "    \n",
    "cv2.imshow('target', target)\n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K - means clustering (평균 군집화) // 비지도 학습\n",
    "\n",
    "src = cv2.imread('image/flower.jpg', 1)\n",
    "\n",
    "data = src.reshape(-1,3).astype(np.float32)\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "retval, bestLabels, centers = cv2.kmeans(data, 11, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "centers = centers.astype(np.uint8)\n",
    "dst = centers[bestLabels].reshape(src.shape)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.2\n",
      "Index : 0\n",
      "예측값 : Ankle boot\n",
      "싧제값 : Ankle boot\n",
      "Index : 1\n",
      "예측값 : Pullover\n",
      "싧제값 : Pullover\n",
      "Index : 2\n",
      "예측값 : Trouser\n",
      "싧제값 : Trouser\n",
      "Index : 3\n",
      "예측값 : Trouser\n",
      "싧제값 : Trouser\n"
     ]
    }
   ],
   "source": [
    "## K - nearest neighbor (최근접 이웃) // 지도학습\n",
    "\n",
    "def loadTrainData(image_path, label_path):\n",
    "\n",
    "    with open(image_path, \"rb\") as image_data:\n",
    "        images = np.frombuffer(image_data.read(), dtype = np.uint8, offset = 16)\n",
    "    with open(label_path, \"rb\") as label_data:\n",
    "        labels = np.frombuffer(label_data.read(), dtype = np.uint8, offset = 8)\n",
    "    return images.reshape(-1, 784), labels\n",
    "\n",
    "train_x, train_y = loadTrainData(\n",
    "    \n",
    "    \"./fashion-mnist/train-images-idx3-ubyte\",\n",
    "    \"./fashion-mnist/train-labels-idx1-ubyte\"\n",
    ")\n",
    "test_x, test_y = loadTrainData(\n",
    "    \n",
    "    \"./fashion-mnist/t10k-images-idx3-ubyte\",\n",
    "    \"./fashion-mnist/t10k-labels-idx1-ubyte\"\n",
    ")\n",
    "label_dict = {\n",
    "    \n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\",\n",
    "    \n",
    "}\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "retval = knn.train(train_x.astype(np.float32), cv2.ml.ROW_SAMPLE, train_y.astype(np.int32))\n",
    "\n",
    "count = 500\n",
    "\n",
    "retval, results, neighborResponses, dist = knn.findNearest(\n",
    "    test_x[:count].astype(np.float32), k = 5\n",
    "    \n",
    ")\n",
    "\n",
    "matches = results.astype(np.uint8) == test_y[:count][:, None]\n",
    "\n",
    "print(np.count_nonzero(matches) / count * 100)\n",
    "\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    print(\"Index : {}\".format(idx))\n",
    "    print(\"예측값 : {}\".format(label_dict[int(result)]))\n",
    "    print(\"싧제값 : {}\".format(label_dict[test_y[idx]]))\n",
    "    cv2.imshow(\"images\", test_x[idx].reshape(28,28,1))\n",
    "    if cv2.waitKey(0) == ord('q') : \n",
    "        break\n",
    "    else :\n",
    "        continue\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optical flow (루카스 - 카나데 알고리즘)\n",
    "\n",
    "cap = cv2.VideoCapture('image/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000/fps)\n",
    "\n",
    "color = (0,255,0)\n",
    "lines = None\n",
    "prevImg = None\n",
    "## calcOpticalFlowPyrLK 중지 요견 설정\n",
    "termcriteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    img_draw = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if prevImg is None:\n",
    "        prevImg = gray\n",
    "        \n",
    "        lines = np.zeros_like(frame)\n",
    "        \n",
    "        prevPt = cv2.goodFeaturesToTrack(prevImg, 200, 0.01, 10)\n",
    "        \n",
    "    else:\n",
    "        nextImg = gray\n",
    "        \n",
    "        nextPt, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, \n",
    "                                                      prevPt, None, \n",
    "                                                      criteria=termcriteria)\n",
    "        \n",
    "        prevMv = prevPt[status==1]\n",
    "        nextMv = nextPt[status==1]\n",
    "        for i,(p, n) in enumerate(zip(prevMv, nextMv)):\n",
    "            px,py = p.ravel()\n",
    "            nx,ny = n.ravel()\n",
    "            \n",
    "            cv2.line(lines, (px.astype(np.uint16),py.astype(np.uint16)), \n",
    "                     (nx.astype(np.uint16),ny.astype(np.uint16)), \n",
    "                     (0,255,0), 2)\n",
    "            \n",
    "            cv2.circle(img_draw, (nx.astype(np.uint16),ny.astype(np.uint16)),\n",
    "                       2, (0,255,0), -1)\n",
    "            \n",
    "        img_draw = cv2.add(img_draw,lines)\n",
    "        \n",
    "        prevImg = nextImg\n",
    "        prevPt = nextMv.reshape(-1,1,2)\n",
    "    \n",
    "    cv2.imshow('OpticalFlow_LK', img_draw)\n",
    "    \n",
    "    if cv2.waitKey(delay) == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(delay) == ord('r'):\n",
    "        prevImg = None\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000001D8D0FCD5C0>\n"
     ]
    }
   ],
   "source": [
    "x = zip(prevMv,nextMv)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prevPt[status==1])\n",
    "print(prevPt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optical flow (군나르 파너백 알고리즘)\n",
    "\n",
    "def drawFlow(img, flow, step = 16):\n",
    "    h,w = img.shape[:2]\n",
    "    \n",
    "    idx_y, idx_x = np.mgrid[step/2:h:step,step/2:w:step].astype(np.int)\n",
    "    indices = np.stack((idx_x, idx_y), axis = -1).reshape(-1,2)\n",
    "    \n",
    "    for x,y in indices:\n",
    "        \n",
    "        cv2.circle(img, (x,y), 1, (0,255,0), -1)\n",
    "        \n",
    "        dx,dy = flow[y, x].astype(np.int)\n",
    "        \n",
    "        cv2.line(img, (x,y), (x+dx, y+dy), (0,255,0),2,cv2.LINE_AA)\n",
    "        \n",
    "prev = None\n",
    "\n",
    "cap = cv2.VideoCapture('image/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000/fps)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret: break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if prev is None:\n",
    "        prev = gray\n",
    "    else :\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev,gray,None,\\\n",
    "                                           0.5,3,15,3,5,1.1,\\\n",
    "                                            cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        drawFlow(frame,flow)\n",
    "        \n",
    "        prev = gray\n",
    "        \n",
    "    cv2.imshow('op', frame)\n",
    "    if cv2.waitKey(delay) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 가우시안 블러\n",
    "\n",
    "img = cv2.imread('image/tomato.jpg', 1)\n",
    "img = cv2.resize(img, dsize=(0,0), fx = 0.5, fy = 0.5,\n",
    "                 interpolation = cv2.INTER_AREA)\n",
    "\n",
    "blur_gaussian = img.copy()\n",
    "blur = img.copy()\n",
    "\n",
    "size = (11,11)\n",
    "\n",
    "blur_gaussian = cv2.GaussianBlur(blur_gaussian, size, sigmaX = 0)\n",
    "blur = cv2.blur(blur, size)\n",
    "\n",
    "cv2.imshow('blur',blur)\n",
    "cv2.imshow('blur_gaussian',blur_gaussian)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
