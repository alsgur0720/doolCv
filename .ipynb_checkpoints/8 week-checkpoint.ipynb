{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40cc7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb159438",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 캐니 엣지 검출 후 매칭\n",
    "\n",
    "img1 = cv2.imread('image/ir test/ir10.jpg',0)\n",
    "img2 = cv2.imread('image/ir test/rgb10.jpg',0)\n",
    "\n",
    "\n",
    "img1_canny = cv2.Canny(img1,125,200, L2gradient = True)\n",
    "img2_canny = cv2.Canny(img2, 200, 400, L2gradient = True)\n",
    "\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "\n",
    "kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n",
    "matches = matcher.match(desc1,desc2)\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [[0,0]],[[0,h]],[[w,h]],[[w,0]] ])\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(dst,pts)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "warp = cv2.warpPerspective(img2, matrix, (w , h))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "matchesMask = mask.ravel().tolist()\n",
    "res2 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                    matchesMask = matchesMask,\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('warp', warp)\n",
    "cv2.imshow('res2 ', res2)\n",
    "cv2.imshow('canny1', img1)\n",
    "cv2.imshow('canny2', img2)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93e3f8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.04725551e+01 -1.43640464e+01  9.57955784e+02]\n",
      " [-5.99476523e+00 -8.29549339e+00  5.50593792e+02]\n",
      " [-1.09752390e-02 -1.49267458e-02  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "693a8c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mask = canny, parameter 수정하여 검출 \n",
    "\n",
    "img1 = cv2.imread('image/ir test/ir2-1.jpg',0)\n",
    "img2 = cv2.imread('image/ir test/rgb2.jpg',0)\n",
    "img2 = cv2.resize(img2, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "img1_canny = cv2.Canny(img1, 50, 130, L2gradient = True)\n",
    "img2_canny = cv2.Canny(img2, 50, 130, L2gradient = True)\n",
    "\n",
    "detector = cv2.xfeatures2d.SIFT_create(contrastThreshold = 0.04)\n",
    "\n",
    "kp1, desc1 = detector.detectAndCompute(img1, mask = img1_canny)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, mask = img2_canny)\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck = True)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "## 특징점 매칭행렬의 원소가 적으면 호모그래피 변환행렬 반환 x\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "\n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [[0,0]],[[0,h]],[[w,h]],[[w,0]] ])\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(dst,pts)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "warp = cv2.warpPerspective(img2, matrix, (w , h))\n",
    "\n",
    "## 상위 특징점만 그린다\n",
    "for i in matches[:100]:\n",
    "    idx_des1 = i.queryIdx\n",
    "    x1, y1, =  kp1[idx_des1].pt\n",
    "    \n",
    "    idx_des2 = i.trainIdx\n",
    "    x2, y2, =  kp2[idx_des2].pt\n",
    "    \n",
    "    cv2.circle(img1, (int(x1), int(y1)), 3, (127, 0, 0), 3)\n",
    "    cv2.circle(img2, (int(x2), int(y2)), 3, (127, 0, 0), 3)\n",
    "    \n",
    "\n",
    "res1 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:100], None,flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('warp', warp)\n",
    "cv2.imshow('res', res1)\n",
    "cv2.imshow('ir_canny', img1_canny)\n",
    "cv2.imshow('rgb_canny', img2_canny)\n",
    "cv2.imshow('ir', img1)\n",
    "cv2.imshow('rgb', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "147ce69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<DMatch 0000024F47369D10>, <DMatch 0000024F47369430>, <DMatch 0000024F477C9590>, <DMatch 0000024F47369C10>, <DMatch 0000024F473697F0>, <DMatch 0000024F47369910>, <DMatch 0000024F477C1AD0>, <DMatch 0000024F473692D0>, <DMatch 0000024F47369CB0>, <DMatch 0000024F47369D30>, <DMatch 0000024F47369BB0>, <DMatch 0000024F47369A50>, <DMatch 0000024F47369890>, <DMatch 0000024F47369CF0>]\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4ed8f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mask = canny, parameter 수정하여 검출 \n",
    "\n",
    "img1 = cv2.imread('image/ir test/ir10-1.jpg',0)\n",
    "img2 = cv2.imread('image/ir test/rgb10-1.jpg',0)\n",
    "img2 = cv2.resize(img2, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "img1_canny = cv2.Canny(img1,20,100, L2gradient = True)\n",
    "img2_canny = cv2.Canny(img2, 30,100, L2gradient = True)\n",
    "\n",
    "detector = cv2.xfeatures2d.SIFT_create(contrastThreshold = 0.09)\n",
    "\n",
    "kp1, desc1 = detector.detectAndCompute(img1, mask = img1_canny)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, mask = img2_canny)\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck = True)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "\n",
    "\n",
    "## 상위 특징점만 그린다\n",
    "for i in matches[:100]:\n",
    "    idx_des1 = i.queryIdx\n",
    "    x1, y1, =  kp1[idx_des1].pt\n",
    "    \n",
    "    idx_des2 = i.trainIdx\n",
    "    x2, y2, =  kp2[idx_des2].pt\n",
    "    \n",
    "    cv2.circle(img1, (int(x1), int(y1)), 3, (127, 0, 0), 3)\n",
    "    cv2.circle(img2, (int(x2), int(y2)), 3, (127, 0, 0), 3)\n",
    "    \n",
    "\n",
    "res1 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:100], None,flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('res', res1)\n",
    "cv2.imshow('ir_canny', img1_canny)\n",
    "cv2.imshow('rgb_canny', img2_canny)\n",
    "cv2.imshow('ir', img1)\n",
    "cv2.imshow('rgb', img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "59a3a82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 52.172462  64.60538 ]]\n",
      "\n",
      " [[ 32.763046 138.9374  ]]]\n"
     ]
    }
   ],
   "source": [
    "print(src_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (몸 검출)\n",
    "\n",
    "cat_face_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')\n",
    "\n",
    "img = cv2.imread('image/ir test/rgb2.jpg', 1)\n",
    "img = cv2.resize(img, dsize = (0,0), fx = 0.5, fy = 0.5, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "body = cat_face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in body :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cb0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 캐니 실험 2\n",
    "\n",
    "img1 = cv2.imread('image/ir test/ir2.jpg',0)\n",
    "img1 = cv2.Canny(img1,125,200, L2gradient = True)\n",
    "\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "\n",
    "cv2.imshow('canny1', img1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5cb47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 캐니 실험 3\n",
    "\n",
    "ir = cv2.imread('image/ir test/ir10-1.jpg', 0)\n",
    "rgb = cv2.imread('image/ir test/rgb10.jpg', 0)\n",
    "\n",
    "rgb_canny = cv2.Canny(rgb, 150,200, L2gradient = True)\n",
    "ir_canny = cv2.Canny(ir, 78, 200, L2gradient = True)\n",
    "\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "kp1, desc1 = detector.detectAndCompute(ir, mask = rgb_canny)\n",
    "kp2, desc2 = detector.detectAndCompute(rgb, mask = ir_canny)\n",
    "\n",
    "matcher = cv2.BFMatcher_create(cv2.NORM_L2)\n",
    "matches = matcher.knnMatch(desc1, desc2, 3)\n",
    "\n",
    "good_matches = []\n",
    "for m in matches:\n",
    "    if m[0].distance / m[1].distance < 0.5:\n",
    "        good_matches.append(m[0])\n",
    "\n",
    "\n",
    "dst = cv2.drawMatches(ir_canny, kp1, rgb_canny, kp2, good_matches, None)\n",
    "\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.imshow('ir', ir)\n",
    "cv2.imshow('rgb',rgb)\n",
    "cv2.imshow('rgb_canny',rgb_canny)\n",
    "cv2.imshow('ir_canny',ir_canny)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ff25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아 시ㅡ발 캐니로 검출하고 knnmatch 까지 해봤는데 안된다 어카지;;\n",
    "## 아 ㅈ 같다 시ㅡ발 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903da030",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 캐니 실험 4\n",
    "\n",
    "ir = cv2.imread('image/ir test/ir10.jpg', 0)\n",
    "rgb = cv2.imread('image/ir test/rgb10.jpg', 0)\n",
    "\n",
    "cv2.imshow('ir', ir)\n",
    "cv2.imshow('rgb',rgb)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e6b5cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\matmul.cpp:2268: error: (-215:Assertion failed) scn + 1 == m.cols in function 'cv::perspectiveTransform'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17424/168639796.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmtrx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPerspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\matmul.cpp:2268: error: (-215:Assertion failed) scn + 1 == m.cols in function 'cv::perspectiveTransform'\n"
     ]
    }
   ],
   "source": [
    "## 매칭\n",
    "\n",
    "img1 = cv2.imread('image/ir test/ir10.jpg',0)\n",
    "img2 = cv2.imread('image/ir test/rgb10.jpg',0)\n",
    "\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "img1_canny = cv2.Canny(img1, 150, 200, L2gradient = True)\n",
    "img2_canny = cv2.Canny(img2, 78, 200, L2gradient = True)\n",
    "\n",
    "kp1, desc1 = detector.detectAndCompute(img1, mask = img1_canny)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, mask = img2_canny)\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck = True)\n",
    "matches = matcher.match(desc1,desc2)\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "\n",
    "\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [[0,0]],[[0,h]],[[w,h]],[[w,0]] ])\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(dst,pts)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "warp = cv2.warpPerspective(img2, matrix, (w , h))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "matchesMask = mask.ravel().tolist()\n",
    "res2 = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
    "                    matchesMask = matchesMask,\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "\n",
    "\n",
    "# 결과 출력                    \n",
    "cv2.imshow('warp', warp)\n",
    "cv2.imshow('res2 ', res2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1407cc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<DMatch 0000024F4884EF10>, <DMatch 0000024F4884EDF0>, <DMatch 0000024F4884EEF0>]\n"
     ]
    }
   ],
   "source": [
    "print(matches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
