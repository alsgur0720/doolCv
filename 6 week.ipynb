{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (고양이 얼굴 검출기)\n",
    "\n",
    "cat_face_cascade = cv2.CascadeClassifier('haarcascade_frontalcatface_extended.xml')\n",
    "\n",
    "img = cv2.imread('image/cats.jpg', 1)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cat_faces = cat_face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in cat_faces :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haar cascade (눈, 얼굴 검출기)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "img = cv2.imread('image/aespa.jpg', 1)\n",
    "img = cv2.resize(img, dsize = (0,0), fx = 0.5, fy = 0.5, interpolation = cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "eyes = eye_cascade.detectMultiScale(gray, 1.1, 3)\n",
    "\n",
    "\n",
    "for (x,y,w,h) in faces :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "    \n",
    "    \n",
    "for (x,y,w,h) in eyes :\n",
    "    \n",
    "    cv2.rectangle(img,(x,y), (x+w,y+h), (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "\n",
    "    \n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORB 알고리즘(Oriented fast and Rotated Breif)\n",
    "\n",
    "src = cv2.imread('image/apple_book.jpg', 1)\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "target = cv2.imread('image/apple.jpg', 0)\n",
    "\n",
    "orb = cv2.ORB_create(\n",
    "    nfeatures = 40000,\n",
    "    scaleFactor = 1.2,\n",
    "    nlevels = 8,\n",
    "    edgeThreshold = 31,\n",
    "    firstLevel = 0,\n",
    "    WTA_K = 2,\n",
    "    scoreType = cv2.ORB_HARRIS_SCORE,\n",
    "    patchSize = 31,\n",
    "    fastThreshold = 20,\n",
    "    \n",
    ")\n",
    "\n",
    "kp1, des1 = orb.detectAndCompute(gray, None)\n",
    "kp2, des2 = orb.detectAndCompute(target, None)\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "for i in matches[:100]:\n",
    "    idx = i.queryIdx\n",
    "    x1, y1, =  kp1[idx].pt\n",
    "    cv2.circle(src, (int(x1), int(y1)), 3, (255, 0, 0), 3)\n",
    "    \n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K - means clustering (평균 군집화) // 비지도 학습\n",
    "\n",
    "src = cv2.imread('image/flower.jpg', 1)\n",
    "\n",
    "data = src.reshape(-1,3).astype(np.float32)\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10, 0.001)\n",
    "retval, bestLabels, centers = cv2.kmeans(data, 5, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "centers = centers.astype(np.uint8)\n",
    "dst = centers[bestLabels].reshape(src.shape)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K - nearest neighbor (최근접 이웃) // 지도학습\n",
    "\n",
    "def loadTrainData(image_path, label_path):\n",
    "    \n",
    "    with open(image_path, \"rb\") as image_data:\n",
    "        images = np.frombuffer(image_data.read(), dtype = np.uint8, offset = 16)\n",
    "        \n",
    "    with open(label_path, \"rb\") as label_data:\n",
    "        labels = np.frombuffer(label_data.read(), dtype = np.uint8, offset = 8)\n",
    "        \n",
    "    return images.reshape(-1, 784), labels\n",
    "\n",
    "\n",
    "train_x, train_y = loadTrainData(\n",
    "    \n",
    "    \"./fashion-mnist/train-images-idx3-ubyte\",\n",
    "    \"./fashion-mnist/train-labels-idx1-ubyte\"\n",
    ")\n",
    "\n",
    "test_x, test_y = loadTrainData(\n",
    "    \n",
    "    \"./fashion-mnist/t10k-images-idx3-ubyte\",\n",
    "    \"./fashion-mnist/t10k-labels-idx1-ubyte\"\n",
    ")\n",
    "\n",
    "\n",
    "label_dict = {\n",
    "    \n",
    "    0: \"T-shirt/top\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle boot\",\n",
    "    \n",
    "}\n",
    "\n",
    "knn = cv2.ml.KNearest_create()\n",
    "retval = knn.train(train_x.astype(np.float32), cv2.ml.ROW_SAMPLE, train_y.astype(np.int32))\n",
    "\n",
    "count = 500\n",
    "\n",
    "retval, results, neighborResponses, dist = knn.findNearest(\n",
    "    test_x[:count].astype(np.float32), k = 7\n",
    "    \n",
    ")\n",
    "\n",
    "matches = results.astype(np.uint8) == test_y[:count][:, None]\n",
    "\n",
    "print(np.count_nonzero(matches) / count * 100)\n",
    "\n",
    "\n",
    "for idx, result in enumerate(results):\n",
    "    print(\"Index : {}\".format(idx))\n",
    "    print(\"예측값 : {}\".format(label_dict[int(result)]))\n",
    "    print(\"싧제값 : {}\".format(label_dict[test_y[idx]]))\n",
    "    cv2.imshow(\"images\", test_x[idx].reshape(28,28,1))\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optical flow (루카스 - 카나데 알고리즘)\n",
    "\n",
    "cap = cv2.VideoCapture('image/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000/fps)\n",
    "\n",
    "color = (0,255,0)\n",
    "lines = None\n",
    "prevImg = None\n",
    "## calcOpticalFlowPyrLK 중지 요견 설정\n",
    "termcriteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    img_draw = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if prevImg is None:\n",
    "        prevImg = gray\n",
    "        \n",
    "        lines = np.zeros_like(frame)\n",
    "        \n",
    "        prevPt = cv2.goodFeaturesToTrack(prevImg, 200, 0.01, 10)\n",
    "        \n",
    "    else:\n",
    "        nextImg = gray\n",
    "        \n",
    "        nextPt, status, err = cv2.calcOpticalFlowPyrLK(prevImg, nextImg, \\\n",
    "                                                      prevPt, None, \\\n",
    "                                                      criteria=termcriteria)\n",
    "        \n",
    "        prevMv = prevPt[status==1]\n",
    "        nextMv = nextPt[status==1]\n",
    "        for i,(p, n) in enumerate(zip(prevMv, nextMv)):\n",
    "            px,py = p.ravel()\n",
    "            nx,ny = n.ravel()\n",
    "            \n",
    "            cv2.line(lines, (px.astype(np.uint16),py.astype(np.uint16)), \\\n",
    "                     (nx.astype(np.uint16),ny.astype(np.uint16)), \\\n",
    "                     (0,255,0), 2)\n",
    "            \n",
    "            cv2.circle(img_draw, (nx.astype(np.uint16),ny.astype(np.uint16)),\\\n",
    "                       2, (0,255,0), -1)\n",
    "            \n",
    "        img_draw = cv2.add(img_draw,lines)\n",
    "        \n",
    "        prevImg = nextImg\n",
    "        prevPt = nextMv.reshape(-1,1,2)\n",
    "    \n",
    "    cv2.imshow('OpticalFlow_LK', img_draw)\n",
    "    \n",
    "    if cv2.waitKey(delay) == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(delay) == ord('r'):\n",
    "        prevImg = None\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prevPt[status==1])\n",
    "print(prevPt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alsgu\\AppData\\Local\\Temp/ipykernel_10860/3754260517.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  idx_y, idx_x = np.mgrid[step/2:h:step,step/2:w:step].astype(np.int)\n",
      "C:\\Users\\alsgu\\AppData\\Local\\Temp/ipykernel_10860/3754260517.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dx,dy = flow[y, x].astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "## optical flow (군나르 파너백 알고리즘)\n",
    "\n",
    "def drawFlow(img, flow, step = 16):\n",
    "    h,w = img.shape[:2]\n",
    "    \n",
    "    idx_y, idx_x = np.mgrid[step/2:h:step,step/2:w:step].astype(np.int)\n",
    "    indices = np.stack((idx_x, idx_y), axis = -1).reshape(-1,2)\n",
    "    \n",
    "    for x,y in indices:\n",
    "        \n",
    "        cv2.circle(img, (x,y), 1, (0,255,0), -1)\n",
    "        \n",
    "        dx,dy = flow[y, x].astype(np.int)\n",
    "        \n",
    "        cv2.line(img, (x,y), (x+dx, y+dy), (0,255,0),2,cv2.LINE_AA)\n",
    "        \n",
    "prev = None\n",
    "\n",
    "cap = cv2.VideoCapture('image/walking.avi')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000/fps)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret: break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if prev is None:\n",
    "        prev = gray\n",
    "    else :\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev,gray,None,\\\n",
    "                                           0.5,3,15,3,5,1.1,\\\n",
    "                                            cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        drawFlow(frame,flow)\n",
    "        \n",
    "        prev = gray\n",
    "        \n",
    "    cv2.imshow('op', frame)\n",
    "    if cv2.waitKey(delay) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 가우시안 블러\n",
    "\n",
    "img = cv2.imread('image/tomato.jpg', 1)\n",
    "img = cv2.resize(img, dsize=(0,0), fx = 0.5, fy = 0.5,\n",
    "                 interpolation = cv2.INTER_AREA)\n",
    "\n",
    "dst = img.copy()\n",
    "\n",
    "dst = cv2.GaussianBlur(dst, (0,0), sigmaX = 10, sigmaY = 2)\n",
    "\n",
    "cv2.imshow('dst',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
