{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c26565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af236104",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ORB 알고리즘(Oriented fast and Rotated Brief)\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "src = cv2.imread('image/rgb2.jpg', 1)\n",
    "src = cv2.resize(src, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "target = cv2.imread('image/ir2.jpg', 0)\n",
    "\n",
    "\n",
    "surf = cv2.xfeatures2d.SURF_create(hessianThreshold = 4000, nOctaves = 4, extended = True, upright = True)\n",
    "\n",
    "kp1, des1 = surf.detectAndCompute(gray, None)\n",
    "kp2, des2 = surf.detectAndCompute(target, None)\n",
    "\n",
    "\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2SQR, crossCheck=True)\n",
    "matches = bf.match(des1,des2)\n",
    "matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in matches[:100]:\n",
    "    idx_des1 = i.queryIdx\n",
    "    x1, y1, =  kp1[idx_des1].pt\n",
    "    \n",
    "    idx_des2 = i.trainIdx\n",
    "    x2, y2, =  kp2[idx_des2].pt\n",
    "    \n",
    "    cv2.circle(src, (int(x1), int(y1)), 3, (0, 0, 0), 3)\n",
    "    cv2.circle(target, (int(x2), int(y2)), 3, (255, 0, 0), 3)\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "src_draw = cv2.drawKeypoints(src, kp2, None,\n",
    "                               flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "target_draw = cv2.drawKeypoints(target, kp2, None,\n",
    "                               flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "\"\"\"\n",
    "res = cv2.drawMatches(src,kp1,target,kp2,matches[:100],None,\n",
    "                     flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "cv2.imshow('res', res)\n",
    "cv2.imshow('target', target)\n",
    "cv2.imshow('src', src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cff7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-contrib-python==3.4.2.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3c2856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 불러오기\n",
    "import sys\n",
    "\n",
    "src1 = cv2.imread('image/rgb3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "src1 = cv2.resize(src1, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "src2 = cv2.imread('image/rgb2.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "src2 = cv2.resize(src2, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "if src1 is None or src2 is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 특징점 알고리즘 객체 생성 (KAZE, AKAZE, ORB 등)\n",
    "#feature = cv2.KAZE_create() # 기본값인 L2놈 이용\n",
    "#feature = cv2.AKAZE_create()\n",
    "feature = cv2.xfeatures2d.SURF_create(upright = True)\n",
    "\n",
    "# 특징점 검출 및 기술자 계산\n",
    "kp1, desc1 = feature.detectAndCompute(src1, None)\n",
    "kp2, desc2 = feature.detectAndCompute(src2, None)\n",
    "\n",
    "# 특징점 매칭\n",
    "matcher = cv2.BFMatcher_create()\n",
    "matches = matcher.match(desc1, desc2)\n",
    "\n",
    "# 좋은 매칭 결과 선별\n",
    "matches = sorted(matches, key=lambda x: x.distance)\n",
    "good_matches = matches[:100]\n",
    "\n",
    "print('# of kp1:', len(kp1))\n",
    "print('# of kp2:', len(kp2))\n",
    "print('# of matches:', len(matches))\n",
    "print('# of good_matches:', len(good_matches))\n",
    "\n",
    "# 호모그래피 계산\n",
    "# DMatch 객체에서 queryIdx와 trainIdx를 받아와서 크기와 타입 변환하기\n",
    "pts1 = np.array([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2).astype(np.float32)\n",
    "pts2 = np.array([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2).astype(np.float32)\n",
    "                \n",
    "H, _ = cv2.findHomography(pts1, pts2, cv2.RANSAC) # pts1과 pts2의 행렬 주의 (N,1,2)\n",
    "\n",
    "# 호모그래피를 이용하여 기준 영상 영역 표시\n",
    "dst = cv2.drawMatches(src1, kp1, src2, kp2, good_matches, None,\n",
    "                      flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "(h, w) = src1.shape[:2]\n",
    "\n",
    "# 입력 영상의 모서리 4점 좌표\n",
    "corners1 = np.array([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]\n",
    "                    ).reshape(-1, 1, 2).astype(np.float32)\n",
    "\n",
    "# 입력 영상에 호모그래피 H 행렬로 투시 변환\n",
    "corners2 = cv2.perspectiveTransform(corners1, H)\n",
    "\n",
    "# corners2는 입력 영상에 좌표가 표현되있으므로 입력영상의 넓이 만큼 쉬프트\n",
    "corners2 = corners2 + np.float32([w, 0])\n",
    "\n",
    "# 다각형 그리기\n",
    "cv2.polylines(dst, [np.int32(corners2)], True, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매칭점 원근 변환으로 영역 찾기 (match_homography.py)\n",
    "\n",
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('image/ir2.jpg')\n",
    "img2 = cv2.imread('image/rgb2.jpg')\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# ORB, BF-Hamming 로 knnMatch  ---①\n",
    "detector = cv2.xfeatures2d.SURF_create(hessianThreshold = 4000, nOctaves = 4, \n",
    "                                       extended = True, upright = True)\n",
    "kp1, desc1 = detector.detectAndCompute(gray1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(gray2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L1)\n",
    "matches = matcher.knnMatch(desc1, desc2, 2)\n",
    "\n",
    "# 이웃 거리의 75%로 좋은 매칭점 추출---②\n",
    "ratio = 0.75\n",
    "good_matches = [first for first,second in matches \\\n",
    "                    if first.distance < second.distance * ratio]\n",
    "print('good matches:%d/%d' %(len(good_matches),len(matches)))\n",
    "\n",
    "# 좋은 매칭점의 queryIdx로 원본 영상의 좌표 구하기 ---③\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches ])\n",
    "# 좋은 매칭점의 trainIdx로 대상 영상의 좌표 구하기 ---④\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches ])\n",
    "# 원근 변환 행렬 구하기 ---⑤\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts)\n",
    "# 원본 영상 크기로 변환 영역 좌표 생성 ---⑥\n",
    "h,w, = img1.shape[:2]\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "# 원본 영상 좌표를 원근 변환  ---⑦\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "# 변환 좌표 영역을 대상 영상에 그리기 ---⑧\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "\n",
    "# 좋은 매칭 그려서 출력 ---⑨\n",
    "res = cv2.drawMatches(img1, kp1, img2, kp2, good_matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "cv2.imshow('Matching Homography', res)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 76,
   "id": "ed52f997",
>>>>>>> 4eff1ec6a884367136cda634ead3f8d568cfc6e9
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 7/295(0.02%)\n"
     ]
    }
   ],
   "source": [
    "import cv2, numpy as np\n",
    "\n",
    "img1 = cv2.imread('image/ir1.jpg',0)\n",
    "img2 = cv2.imread('image/rgb2.jpg',0)\n",
    "img2 = cv2.resize(img2, dsize = (0,0), fx = 0.5, fy = 0.5)\n",
    "\n",
    "\n",
    "# knnMatch  ---①\n",
    "##detector = cv2.xfeatures2d.SURF_create(hessianThreshold = 100, nOctaves = 3,extended = False, upright = False)\n",
    "detector = cv2.xfeatures2d.SIFT_create()\n",
    "##detector = cv2.ORB_create( nfeatures = 40000 )\n",
    "\n",
    "kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "matcher = cv2.BFMatcher(cv2.NORM_L1, crossCheck = True)\n",
    "matches = matcher.match(desc1, desc2)\n",
    "# 매칭 결과를 거리기준 오름차순으로 정렬 ---③\n",
    "matches = sorted(matches, key=lambda x:x.distance)\n",
    "# 모든 매칭점 그리기 ---④\n",
    "res1 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# 매칭점으로 원근 변환 및 영역 표시 ---⑤\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in matches ]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "\n",
    "# RANSAC으로 변환 행렬 근사 계산 ---⑥\n",
    "mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "h,w = img1.shape\n",
    "pts = np.float32([ [[0,0]],[[0,h-1]],[[w-1,h-1]],[[w-1,0]] ])\n",
    "dst = cv2.perspectiveTransform(pts,mtrx)\n",
    "\n",
    "matrix = cv2.getPerspectiveTransform(dst,pts)\n",
    "img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)\n",
    "warp = cv2.warpPerspective(img2, matrix, (w , h))\n",
    "\n",
    "\n",
    "\n",
    "# 정상치 매칭만 그리기 ---⑦\n",
    "matchesMask = mask.ravel().tolist()\n",
    "res2 = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, \\\n",
    "                    matchesMask = matchesMask,\n",
    "                    flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "\n",
    "\n",
    "# 모든 매칭점과 정상치 비율 ---⑧\n",
    "accuracy=float(mask.sum()) / mask.size\n",
    "print(\"accuracy: %d/%d(%.2f%%)\"% (mask.sum(), mask.size, accuracy))\n",
    "\n",
    "# 결과 출력                    \n",
    "cv2.imshow('warp', warp)\n",
    "cv2.imshow('Matching-All', res1)\n",
    "cv2.imshow('Matching-Inlier ', res2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70408547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.30654563e+00 -2.94097148e+00  3.25061099e+02]\n",
      " [-8.43377605e+00 -3.04683474e+00  5.12082904e+02]\n",
      " [-1.70070224e-02 -5.73678790e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(mtrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c992691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
